{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c32d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495eb926-1a85-48df-a22c-ae5be25daffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Wine.csv')\n",
    "X = dataset.iloc[:, 0:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2abe8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split and scale ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4b76dc-8d6d-4fec-962d-5e2d796d9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define classifiers ---\n",
    "models = {\n",
    "    'Logistic': LogisticRegression(random_state=0),\n",
    "    'SVMl': SVC(kernel='linear', random_state=0),\n",
    "    'SVMnl': SVC(kernel='rbf', random_state=0),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),\n",
    "    'Navie': GaussianNB(),\n",
    "    'Decision': DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "    'Random': RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "}\n",
    "\n",
    "# --- Different PCA component counts ---\n",
    "pca_components = [2, 3, 4, 5]\n",
    "\n",
    "# --- Result table ---\n",
    "pca_results = pd.DataFrame(columns=list(models.keys()) + ['Explained_Variance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f270d0-a6f4-4879-8f55-e9ce29f512fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final PCA-based Accuracy Table:\n",
      "\n",
      "      Logistic   SVMl  SVMnl    KNN  Navie Decision Random  \\\n",
      "PCA_2    0.978  0.978  0.978  0.978  0.978    0.978  0.978   \n",
      "PCA_3    0.978    1.0    1.0    1.0    1.0    0.956  0.956   \n",
      "PCA_4    0.978  0.956  0.978  0.956    1.0    0.978  0.911   \n",
      "PCA_5    0.978  0.956    1.0    1.0    1.0    0.978  0.978   \n",
      "\n",
      "                                      Explained_Variance  \n",
      "PCA_2               [0.37281068 0.18739996] (Total=0.56)  \n",
      "PCA_3    [0.37281068 0.18739996 0.10801208] (Total=0.67)  \n",
      "PCA_4  [0.37281068 0.18739996 0.10801208 0.07619859] ...  \n",
      "PCA_5  [0.37281068 0.18739996 0.10801208 0.07619859 0...  \n"
     ]
    }
   ],
   "source": [
    "for n in pca_components:\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    \n",
    "    row_name = f\"PCA_{n}\"\n",
    "    pca_results.loc[row_name, 'Explained_Variance'] = f\"{explained_var} (Total={sum(explained_var):.2f})\"\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        pca_results.loc[row_name, name] = round(acc, 3)\n",
    "\n",
    "print(\"\\nFinal PCA-based Accuracy Table:\\n\")\n",
    "print(pca_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc213d-0812-445d-b3db-c50f6ec659cf",
   "metadata": {},
   "source": [
    "The provided image shows the results of a Principal Component Analysis (PCA) used to preprocess data for several machine learning classification models. The tables display the accuracy and explained variance for each model when using a different number of principal components.\n",
    "\n",
    "The table compares the accuracy of seven different classification models (Logistic, SVMl, SVMnl, KNN, Naive, Decision, and Random) using 2, 3, 4, or 5 principal components (PCA_2 to PCA_5).\n",
    "\n",
    "PCA_2: All models achieve an accuracy of 0.978, which indicates that using only the first two principal components is highly effective for this dataset.\n",
    "\n",
    "PCA_3: The accuracy for most models (SVMl, SVMnl, KNN, and Naive) increases to 1.0 (100%), while Logistic remains at 0.978. Decision and Random model accuracy drops to 0.956. This suggests that adding a third principal component significantly improves the performance for some models, while causing a slight decrease for others, possibly due to the introduction of noise.\n",
    "\n",
    "PCA_4 and PCA_5: The accuracy values become more varied across the models as more components are added. This highlights a trade-off: while more components retain more information, they can also introduce noise that may cause the models to overfit or perform inconsistently. For example, the Decision model's accuracy increases to 1.0 with PCA_4 but then drops slightly with PCA_5, while the Random model's accuracy consistently decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6f818-3763-43e4-88e1-5c8b175a82f4",
   "metadata": {},
   "source": [
    "Analysis of Explained Variance\n",
    "\n",
    "The bottom table shows the explained variance, which measures how much of the original data's total variance is captured by the selected principal components.\n",
    "\n",
    "PCA_2: The first two principal components capture a total of 56% of the variance in the data.\n",
    "\n",
    "PCA_3: Adding the third principal component brings the cumulative explained variance up to 67%.\n",
    "\n",
    "PCA_4: The cumulative explained variance increases to 74.6% with the addition of the fourth component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7b929-8f3a-4acb-bf64-9f397c25d2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88ea0a-b166-4e4d-9555-9df2ab5fa36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
